{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset Research**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying and Defining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **The Scenario and Purpose**\n",
    "##### My chosen scenario is the cost of using a car, which is based on many factors including current price, fuel type, seller type and transmission. With this dataset, I can analyse the data to find out what factors are influencing the cost of different models of cars spread across different dates. The data is accessible publicly on Kaggle, and can be downloaded as a CSV. I will analyse the data in its CSV format. \n",
    "##### The link to the dataset is https://www.kaggle.com/datasets/zahrayazdani81/carsdataset/data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Requirements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Loading**\n",
    "##### To ensure the data is suitable for analysis, the dataset needs to be imported as an appropiate file format. The dataset for analysis would be in a CSV format.\n",
    " * The user will need to **input** an appropiate file format (CSV, preferrably).\n",
    " * There wouldn't be an **output**, but to ensure the file can be read with Pandas, the CSV must have accurate data placement in regards with commas, to make sure rows and columns are readable to the computer.\n",
    "#### **Data Cleaning** \n",
    "##### The system also needs to be able to allow filtering, sorting and grouping to enable successful analysis. The dataset also needs to be \"organised\" in a way that removes incorrect or invalid pieces of data before the analysis occurs, to ensure accurate results.\n",
    " * The **user** will need to either run a process that uses Pandas to filter data, or they can use a spreadsheet program, such as Excel, and utilise it to filter out the invalid information.\n",
    " * The program should be able to **output** a correct and clean dataset. \n",
    "#### **Data Analysis**\n",
    "##### The statistical analysis needs to conduct a variety of different processes to output useful results. These process include the mean, median and mode for various columns in the dataset, such as mileage and price. However, mean and median may only be able to be analysed for numerical data. For non-numerical data, most frequent and infrequent values can also be analysed.\n",
    " * The **user** will need to run a program where it is capable of analysing data. \n",
    " * The program will need to **output** the necessary analysis results requested by the user. It may be sorted into variables into a dataset.\n",
    "#### **Data Visualisation**\n",
    "##### The data will be visualised mainly through Matplotlib graphs. With the use of dataframes (another method of visualisation) and datasets to store data, graphs can be created as an easy and consumable method of visualising large amounts of the data.\n",
    " * The **user** will need to specify what kind of graph through the Matplotlib module. They may also request a table of summary.\n",
    " * The program will need to **output** the specified graph or table.\n",
    "#### **Data Reporting**\n",
    "##### The system will need to create some statistical information relating to the dataset (quantity of rows, columns, mean, etc.) will also be a part of the output results, as an extra summary of the information. Data reporting can also be outside of the program, where written reports can be created based on the information gathered fro the analysis.\n",
    "\n",
    "\n",
    " * The **user** will need to request statistical information from the program.\n",
    " * The program will need to **output** the requested statistical information, making sure it is correct/valid. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Loading**\n",
    "##### **Actor:** Data Analysist or User\n",
    "##### **Goal:** To import a correct file format as a dataset into the system.\n",
    "##### **Preconditions:** User has a dataset ready to be imported.\n",
    "> ##### 1. User imports the dataset into the correct folder to be read. \n",
    "> ##### 2. System reads and validates the dataset\n",
    "> ##### 3. System displays the dataset in a dataframe\n",
    "#####  **Postconditions:** Dataset is ready for the next steps of analysis.\n",
    "#### **Data Cleaning**\n",
    "##### **Actor:** Data Analysist\n",
    "##### **Goal:** For the system to filter out incorrect, misplaced or broken data out of the dataset.\n",
    "##### **Preconditions:** The system already has a dataset imported\n",
    "> ##### 1. Data analysist runs a program that filters out invalid data.\n",
    "> ##### 2. (If required) Data analysist manually cleans some portions of the dataset\n",
    "> ##### 3. The system is able to present the cleaned dataset as a valid dataframe. \n",
    "##### **Postconditions:** Data has been filtered and cleaned.\n",
    "#### **Data Analysis**\n",
    "##### **Actor:** Data Analysist\n",
    "##### **Goal:** To analyse the data to extract important pieces of it and make summaries\n",
    "##### **Preconditions:** The selected dataset has already been cleaned; ready for analysis. There should also be a program that analyses the data.\n",
    "> ##### 1. Data analysist runs a program that analyses the data.\n",
    "> ##### 2. System runs the analysis.\n",
    "> ##### 3. System prints out the requested data for analysis (e.g. mean, median, categories)\n",
    "##### **Postconditions:** The system outputs the requested analysis.\n",
    "#### **Data Visualisation**\n",
    "##### **Actor:** Data Analysist or User\n",
    "##### **Goal:** The system outputs a readable graph that visualises the trends of the data.\n",
    "##### **Preconditions:** The data has been cleaned and formatted correctly, but it may not necessarily have to go through an analysis.\n",
    "> ##### 1. Data analysist requests the specified visualisation\n",
    "> ##### 2. System validates the requested visualisaton\n",
    "> ##### 3. System outputs the visualisation\n",
    "##### **Postconditions:** The requested visualisation is the output.\n",
    "#### **Data Reporting**\n",
    "##### **Actor:** Data Analysist\n",
    "##### **Goal:** To extract statistical information on the dataset (quanity of rows, columns etc.)\n",
    "##### **Preconditions:** Dataset has already been cleaned and formatted correctly.\n",
    "> ##### 1. Data analysist requests the desired statistical information\n",
    "> ##### 2. System checks dataset/dataframe for the information\n",
    "> ##### 3. System outputs the statistical information\n",
    "##### **Postconditions:** The correct and desired statistical information is the output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Non-functional requirements**\n",
    "##### **Usability**\n",
    "##### The user-interface should be able to perform a number of tasks efficiently, including menus, buttons, and navigation bars. It should also be easy to navigate to different tasks, making seamless user experience. Having a user-interface also makes it easier for the user to understand how to perform different tasks, without having to spend an excessive amount of time trying to figure out how to do a certain task. A **READ ME** document is also very helpful, as it provides the user with some context, background information, and even instructions on how to use the program or UI. A README document should contain background information, instructions, support, and even some legal information if needed.\n",
    "##### **Reliability**\n",
    "##### When errors are found, the system should give some technical information about the error, as well as suggesting some solutions on resolving the error. The technical information is important as it gives an idea of where the error may be found. These reliability factors are essential when the system needs to give information about an error.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research of Chosen issue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Purpose**\n",
    "##### My chosen issue was the cost of using cars. Conducting an analysis on this issue has a purpose, which is revealing hidden factors of the cost of using cars that many people may not know about. Further research should be conducted on this issue as it may guide people on what factors to look out for when trying to use a car as a method of transportation. It has the potential to assist them when considering to use a car.\n",
    "#### **Missing Data**\n",
    "##### I think it is necessary to carry out this analysis because of its real-world applications, which is also what the dataset was made for. WHen I researched some of the current data and information about the cost of using cars, I found that some of the sources did not include specific prices (selling and current price), specific car models and some of the different years these cars costed to use.\n",
    "#### **Stakeholders** \n",
    "##### Some small businesses and entrepeneurs may benefit from my information. People who are considering to purchase cars may also benefit from the information,\n",
    "#### **Use**\n",
    "##### Businesses and entrepeneurs are able to benefit from my information by discovering trends and patterns by analyzing the results. People who are looking to purchase cars may also use this information, where they can analyse various factors that influence the price of cars, assisting their decisions when it comes to purchasing them.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Privacy and Security"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Privacy of Source**\n",
    "##### My chosen dataset was sourced fromm Kaggle. Kaggle, as a host for datasets and machine-learning, has multiple responsibilities when it comes to protecting participants' and users' privacy. One of the most important data to protect is account data, whether they are passwords, emails or contact information. This collection of data should be minimised incase of potential data breaches. Kaggle must also keep usage data private and minimised as much as possible. It includes documenting activity and actions on the platform. As a platform that is responsible for holding sensitive information, Kaggle must also be transparent about their collection practices to their users and participants, so that they are well informed on what they may be revealing about their personal information,\n",
    "#### **Application Data Privacy**\n",
    "##### My responsibilites for maintaining the privacy of this dataset mainly revolve around participants who gave their information in the creation of this data. Some data is identifiable, if it reveals information about who actually gave it away. If I were to push this application to the public, I'll ensure all information is kept relevant to its use, while remaining transparent about collected user data and minimise it.\n",
    "#### **Cyber Security**\n",
    "##### To maintain cyber security in an application, its important to protect sensitive information. Firstly, an application should have a secure login process (if needed), which ensures the user to have a strong password, and even multi-factor authentication to add bonus layers of security. Data should allso be encrypted, to keep out unauthorized access. Applications should have constant monitering of activity within its servers and programs, to detect suspicious or dangerous activity early. Lastly, developers and managers of applications should regularly update their security practices, ensuring it is up to date with as little potential errors as possible, maintaining security of the data. These are all essential cybersecurity features within applications.\n",
    "* #### **User Authentication:** A process that verifies a user's identity, granting access to online applications or other resources.\n",
    "* #### **Password Hashing:** A security action that turns a password into a string of letters and numbers using an encyption algorithm, to ensure a secure password.\n",
    "* #### **Encryption:** A form of data security in which information is converted into ciphertext. Only authorized users are able to decipher the encrypted information to obtain the original plaintext."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Field    | Datatype | Format for Display | Description                  | Example | Validation                                                     |\n",
    "| :- | :- | :- | :- | :- | :- |\n",
    "| Car Name | object   | XX....XX          | The name of the car's model. | Swift   | Can be any amount of characters, but must not include numbers. |\n",
    "| Year | int64 | YYYY | Determines the year the model's data was recorded | 2014 | Can only be used in a YYYY format, and must not contain any characters other than whole numbers. |\n",
    "| Selling Price | float64 | NN.NN | The selling price of the car, marking its true value (in lakh INR) | 3.35 | Must always be a float, without exceeding 2 decimal places. |\n",
    "| Present Price | float64 | NN.NN | The current price of the car, according to the year (in lakh INR) | 23.15 | Must always be a float, without exceeding 2 decimal places. |\n",
    "| Kilometres Driven | int64 | NN....NN | How many kilometres the used car has driven. | 51000 | Can only be an integer. |\n",
    "| Fuel Type | object | XXXXXX | The type of fuel the car uses. | Diesel | Must only be either diesel or petrol. Cannot contain any numbers. |\n",
    "| Seller Type | object | XXXXXX... | Who sold the car to their respective owner. | Dealer | Can only be an object. Must not contain any numbers. | \n",
    "| Transmission | object | XXXXXX... | The type of transmission of the car model. | Manual | Can only be either Manual or Automatic. Must not contain any numbers. |\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Privacy of Source**\n",
    "##### My chosen dataset was sourced fromm Kaggle. Kaggle, as a host for datasets and machine-learning, has multiple responsibilities when it comes to protecting participants' and users' privacy. One of the most important data to protect is account data, whether they are passwords, emails or contact information. This collection of data should be minimised incase of potential data breaches. Kaggle must also keep usage data private and minimised as much as possible. It includes documenting activity and actions on the platform. As a platform that is responsible for holding sensitive information, Kaggle must also be transparent about their collection practices to their users and participants, so that they are well informed on what they may be revealing about their personal information,\n",
    "#### **Application Data Privacy**\n",
    "##### My responsibilites for maintaining the privacy of this dataset mainly revolve around participants who gave their information in the creation of this data. Some data is identifiable, if it reveals information about who actually gave it away. If I were to push this application to the public, I'll ensure all information is kept relevant to its use, while remaining transparent about collected user data and minimise it.\n",
    "#### **Cyber Security**\n",
    "##### To maintain cyber security in an application, its important to protect sensitive information. Firstly, an application should have a secure login process (if needed), which ensures the user to have a strong password, and even multi-factor authentication to add bonus layers of security. Data should allso be encrypted, to keep out unauthorized access. Applications should have constant monitering of activity within its servers and programs, to detect suspicious or dangerous activity early. Lastly, developers and managers of applications should regularly update their security practices, ensuring it is up to date with as little potential errors as possible, maintaining security of the data. These are all essential cybersecurity features within applications.\n",
    "* #### **User Authentication:** A process that verifies a user's identity, granting access to online applications or other resources.\n",
    "* #### **Password Hashing:** A security action that turns a password into a string of letters and numbers using an encyption algorithm, to ensure a secure password.\n",
    "* #### **Encryption:** A form of data security in which information is converted into ciphertext. Only authorized users are able to decipher the encrypted information to obtain the original plaintext."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Sebastian Tam** - For the functional requirements, I believe that Ray has successfully addressed these. For data loading, the data is loaded as a csv file. In regards to data cleaning, Ray has dropped a column that he didn't need, and also put on_bad_lines='warn'. For data analysis, the programs provide statistical data, so you can see the result. There are also matplotlib charts for some data so that we can visually see it. Ray has data reporting in his code as there is an option to show the general information of the dataset. For non-functional requirements, the data is usable, as there is a UI interface so that the user can operate the data. Ray also has a README file so that the user knows how to operate it incase it doesn't know. The data is reliable, as it shows if there is an error, but there were no errors in the User Interface when I tested it.\n",
    "##### **Levin Shao** - In terms of the functional requirements, Ray has done a very good job addressing these. He is able to load the data into a csv file, he was able to clean the data and filter it into a neater dataset. Ray has removed any unnecessary data, making the dataframe very neat, and has made the User Interface very friendly to use. The program has provided statistical data, allowing you to view the results very easily. Ray has also done a very good job at using Matplotlib to visualize the data. The data graph was very neat and easy to understand. In terms of the non-functional requirements, the data is very usable, and the user interface is able to demonstrate every option available for the dataframe. Ray has also written a very clear README file containing neat instructions for their users to read, which is brilliant.\n",
    "##### **Darrell Campoy** -  Ray Wong’s UI successfully meets both his functional and non-functional requirements. His program shows a good level of sophistication and meets all his determined criteria. The program appeals to his non-functional requirements as the UI is efficient and easy to use. He also has a clear README which gives instructions on how to use the program. Overall, Ray’s program is very successful in achieving what he aimed to achieve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse and Conclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data visualisation**\n",
    "##### Selling Price over the years\n",
    "![Selling Price over the years](images/sell_price_yr.png)\n",
    "##### Present Price over the years\n",
    "![Present Price over the years](images/pres_price_yr.png)\n",
    "##### Relationship between transmission and present price \n",
    "![Relationship between transmission and present price](images/transmission_sell.png)\n",
    "##### Selling price - yearly average\n",
    "![Selling Price yearly average](images/avg_yr.png)\n",
    "\n",
    "#### **Calculations (only including thee statistical options)**\n",
    "* ##### Average selling Price - This option takes the selling price column and calculates the mean, and does an AUD conversion to get the Australian price.\n",
    "* ##### Average present price - This option takes the present price column and calculates the mean, and does an AUD conversion to get the Australian price.\n",
    "* ##### Automatic and Manual cars - This option counts how many objects that either say 'Automatic' or 'Manual' there are.\n",
    "* ##### Most and least expensive cars - This option checks the column and row that has the lowest and highest values of the price (column) and returns the Car's Name. It is for both 'Selling Price' and 'Present Price'.\n",
    "##### Accuracy: Overall, these calculations were very accurate, in terms of analysing the dataframe itself. It checks every value in the dataset necessary and outputs its exact calculation based on the findings. It makes sure to check for any invalid lines (rows), to ensure accurate results. \n",
    "\n",
    "#### **Conclusion**\n",
    "##### Overall, I think the overall analysis was a success. From the data that the analysis provides, I was able to conclude the most expensive and least expensive cars in the region (India). With the help from the data visualisations, I was able to draw some conclusions. Firstly, it seemed like the selling price rose but the present price didn't, which might suggest there are economical imbalances within the car industry, where it may cost producers more to manufacture than to sell. I could also see the production of automatic cars had bigger ranges in terms of their selling price. The yeatly average selling price, however, seems to be an unstable yet definite rise, which might suggest producers are raising the prices for consumers, even if the present price stays relatively consistent. This information is, in my opinion, useful for those discovering the trends in the car industry (people who run some sort of business relating to cars). It may also be useful for those who are interested in the car industry and those considering to purchase a car. Overall, this analysis was a success, where I was able to discover trends and patterns that the dataset contained, and I was able to draw conclusions supported with reasoning.\n",
    "\n",
    "#### **Evaluation of Final Product in Relation to Functional and Non-Functional Requirements**\n",
    "##### Regarding the evaluation of my final product, my text-based User Interface was successful in completing the functional and non-functional requirements. Here's how.\n",
    "##### Firstly, the functional requirements. I loaded the correct file format (.CSV file), which enabled the system to read the file without any problems. Then, in order to filter the dataset, I dropped the column ‘Owner’ (as it was not needed), and I also made sure that the system would warn the user for any bad lines, ensuring its validity for the analysis process. After filtering the data, I developed the User Interface that contained a variety of different options for analysis, outputting the requested analysis and running accurate calculations. I also added some data visualisation options, in order to help the user spot trends and patterns within the data. To report the data’s general statisitcs, I added an option that displays that information (e.g. types of data forms). This is what enabled me to fulfill my functional requirements.\n",
    "##### Regarding non-functional requirements, I ensured to make the User Interface as easy as possible to use. I did this by letting the user know which numbers would output which analysis option, as well as adding sub-options to ensure the UI looked neat and organised, as well as making the program more user friendly and seamless. I included a README document as well, which contains the link to the CSV, instructions and background information, in case the user was interested. \n",
    "##### Overall, I believe that I have achieved all my functional and non-functional requirements. I ensured the User Interface addressed each and every requirement, making this program a valid tool for data analysis.\n",
    "\n",
    "#### **Evaluation of the Project in Relation to Testing and Project Management**\n",
    "##### There were multiple challenges and time constraints, regarding the project management and testing.\n",
    "##### Time management was a fairly large concern during the development of this project. Due to insufficient planning, the producing and implementing stage of the project was commenced at a late time, which ended up creating a time concern. It was a little bit stressful to produce an effective product in the time that I was given, and there were many issues when programming the UI. Because of this, it impacted the last stage's development (Testing and Evaluating), putting even more stress on completing the project. However, I still managed to complete this project with some assistance from my peers, who helped guide me, resulting in success of completion. \n",
    "##### During the testing stage, there many errors, including an issue trying to install pip on a machine at home. It was a setback, resulting in the cost of a precious amount of time. However, after resolving the issue, I stiil overcame the challenge by completing my User Interface more efficiently with the help of online documentation and my peers. This helped me produce a program that met all my function and non-functional requirements.\n",
    "##### Overall, the project presented a particularly bumpy journey, through researching, producing and testing. While it presented these challenges along with a time struggle, I still managed to overcome them by implementing better efficiency in the late stage of the project. I aim to develop better planning skills for future projects, to ensure that I am able to overcome practical problems and solve them in a timely manner. It was overall a successful yet challenging project.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
